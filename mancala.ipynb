{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10000 trials with depth = 1...\n",
      "Progress: 10000/10000 trials run (100.00%) | Elapsed: 00:00:23 | ETA: 00:00:00\n",
      "============================================================\n",
      "TRIAL RESULTS\n",
      "============================================================\n",
      "\n",
      "Total Games Played: 10000\n",
      "\n",
      "Win Statistics:\n",
      "  Player 1 Wins: 9985 (99.9%)\n",
      "  Player 2 Wins:      14 (0.1%)\n",
      "  Ties:               1 (0.0%)\n",
      "\n",
      "Score Difference Statistics (P1 - P2):\n",
      "  Total Sum:      232179\n",
      "  Average:        23.22\n",
      "  Std Dev:        6.06\n",
      "  Min:            -9\n",
      "  Max:            41\n",
      "\n",
      "Moves Statistics:\n",
      "  Average P1 Moves per Game:     19.14\n",
      "  Average P2 Moves per Game:     13.88\n",
      "  Average Total Moves per Game: 33.03\n",
      "  Total P1 Moves (all games):    191437\n",
      "  Total P2 Moves (all games):    138826\n",
      "  Total Moves (all games):       330263\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from games import Game, GameState\n",
    "\n",
    "random.seed()\n",
    "\n",
    "def minmax_decision(state, game, depthLim = 3):\n",
    "    \"\"\"Given a state in a game, calculate the best move by searching\n",
    "    forward all the way to the terminal states. [Figure 5.3]\"\"\"\n",
    "\n",
    "    player = game.to_move(state)\n",
    "\n",
    "    def max_value(state, depthLimIn):\n",
    "        if game.terminal_test(state) or depthLimIn <=0:\n",
    "            return game.utility(state, player)\n",
    "        v = -np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = max(v, min_value(game.result(state, a), depthLimIn-1))\n",
    "        return v\n",
    "\n",
    "    def min_value(state, depthLimIn):\n",
    "        if game.terminal_test(state) or depthLimIn <=0:\n",
    "            return game.utility(state, player)\n",
    "        v = np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = min(v, max_value(game.result(state, a), depthLimIn -1))\n",
    "        return v\n",
    "\n",
    "    return max(game.actions(state), key=lambda a: min_value(game.result(state, a), depthLim))\n",
    "\n",
    "\n",
    "def alpha_beta_search(state, game, depth_limit=10):\n",
    "    \"\"\"Search game to determine best action; use alpha-beta pruning.\n",
    "    As in [Figure 5.7], this version searches all the way to the leaves.\"\"\"\n",
    "\n",
    "    player = game.to_move(state)\n",
    "\n",
    "    def max_value(state, alpha, beta, depth):\n",
    "        if depth <= 0 or game.terminal_test(state):\n",
    "            return game.utility(state, player)\n",
    "        v = -np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = max(v, min_value(game.result(state, a), alpha, beta, depth - 1))\n",
    "            if v >= beta:\n",
    "                return v\n",
    "            alpha = max(alpha, v)\n",
    "        return v\n",
    "\n",
    "    def min_value(state, alpha, beta, depth):\n",
    "        if depth <= 0 or game.terminal_test(state):\n",
    "            return game.utility(state, player)\n",
    "        v = np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = min(v, max_value(game.result(state, a), alpha, beta, depth - 1))\n",
    "            if v <= alpha:\n",
    "                return v\n",
    "            beta = min(beta, v)\n",
    "        return v\n",
    "\n",
    "    best_score = -np.inf\n",
    "    beta = np.inf\n",
    "    best_action = None\n",
    "    for a in game.actions(state):\n",
    "        v = min_value(game.result(state, a), best_score, beta, depth_limit)\n",
    "        if v > best_score:\n",
    "            best_score = v\n",
    "            best_action = a\n",
    "    return best_action\n",
    "\n",
    "def random_player(game, state, depth):\n",
    "    \"\"\"A player that chooses a legal move at random.\"\"\"\n",
    "    return random.choice(game.actions(state)) if game.actions(state) else None\n",
    "\n",
    "\n",
    "def alpha_beta_player(game, state, depth):\n",
    "    return alpha_beta_search(state, game, depth)\n",
    "\n",
    "\n",
    "def minmax_player(game,state, depth):\n",
    "    return minmax_decision(state,game, depth)\n",
    "\n",
    "\n",
    "class Mancala(Game):\n",
    "    def __init__(self, players = [alpha_beta_player, random_player], pits_per_player=6, stones_per_pit = 4, depth = 5):\n",
    "        self.pits_per_player = pits_per_player\n",
    "        self.board = [stones_per_pit] * ((pits_per_player+1) * 2)\n",
    "        \n",
    "        self.current_player = 1\n",
    "        self.moves = []\n",
    "        self.p1_pits_index = [0, self.pits_per_player-1]\n",
    "        self.p1_mancala_index = self.pits_per_player\n",
    "        self.p2_pits_index = [self.pits_per_player+1, len(self.board)-1-1]\n",
    "        self.p2_mancala_index = len(self.board)-1\n",
    "\n",
    "        # Total stones in the game (used in utility function)\n",
    "        self.total_stones = pits_per_player * stones_per_pit\n",
    "        \n",
    "        self.board[self.p1_mancala_index] = 0\n",
    "        self.board[self.p2_mancala_index] = 0\n",
    "        \n",
    "        self.initial = GameState(to_move = \"1\", utility = 0, board = self.board.copy(), moves=())\n",
    "        self.state = self.initial\n",
    "        \n",
    "        self.players = players\n",
    "        self.depth = depth\n",
    "        \n",
    "        # Track moves per player\n",
    "        self.p1_moves = 0\n",
    "        self.p2_moves = 0\n",
    "\n",
    "    def valid_move(self, pit, state):\n",
    "        \"\"\"\n",
    "        Function to check if the pit chosen by the current_player is a valid move.\n",
    "        \"\"\"\n",
    "        if state.to_move == \"1\":\n",
    "            pit_index = pit - 1\n",
    "            if pit_index < self.p1_pits_index[0] or pit_index > self.p1_pits_index[1]:\n",
    "                return False\n",
    "        else:\n",
    "            pit_index = self.p2_pits_index[1] - (pit - 1)\n",
    "            if pit_index < self.p2_pits_index[0] or pit_index > self.p2_pits_index[1]:\n",
    "                return False\n",
    "        \n",
    "        return list(state.board)[pit_index] > 0\n",
    "    \n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"Function to verify if the game board has reached the winning state.\"\"\"\n",
    "        board = list(state.board) if state.board else self.board\n",
    "        \n",
    "        p1_pits_sum = sum(board[self.p1_pits_index[0]:self.p1_pits_index[1]+1])\n",
    "        p2_pits_sum = sum(board[self.p2_pits_index[0]:self.p2_pits_index[1]+1])\n",
    "        \n",
    "        return p1_pits_sum == 0 or p2_pits_sum == 0\n",
    "    \n",
    "    def actions(self, state):\n",
    "        \"\"\"Return a list of the allowable moves at this point.\"\"\"\n",
    "        val = []\n",
    "        for pit in range(1, self.pits_per_player + 1):\n",
    "            if (self.valid_move(pit, state)): \n",
    "                val.append(pit)\n",
    "        return val\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Return the value of this final state to player.\"\"\"\n",
    "        board = list(state.board)\n",
    "\n",
    "        # Compute sum of remaining stones on the board and calculate the ratio of stones left in the game\n",
    "        # Serves as a ratio to reflect percentage left in the game\n",
    "        p1_pits_sum = sum(board[self.p1_pits_index[0]:self.p1_pits_index[1]+1])\n",
    "        p2_pits_sum = sum(board[self.p2_pits_index[0]:self.p2_pits_index[1]+1])\n",
    "\n",
    "        stones_left_ratio = (p1_pits_sum + p2_pits_sum) / self.total_stones\n",
    "\n",
    "        # If the game is at least 90% over, include weighting so utility function takes into consideration:\n",
    "        # 1. The difference of stones on each side of the board \n",
    "        # 2. AND the difference of stones in each mancala\n",
    "        \n",
    "        if stones_left_ratio <= 0.1:\n",
    "            weighted_utilities = [0.1 - stones_left_ratio, stones_left_ratio + 0.9]\n",
    "        else:\n",
    "            weighted_utilities = [0, 1]\n",
    "\n",
    "        if (player == \"1\"): \n",
    "            return weighted_utilities[0] *  (p1_pits_sum - p2_pits_sum) + weighted_utilities[1] * (board[self.p1_mancala_index] - board[self.p2_mancala_index])\n",
    "        else: return weighted_utilities[0] * (p2_pits_sum - p1_pits_sum) + weighted_utilities[1] * (board[self.p2_mancala_index] - board[self.p1_mancala_index])\n",
    "\n",
    "    def result(self, state, move):\n",
    "        \"\"\"Return the state that results from making a move from a state.\"\"\"\n",
    "        board = list(state.board)\n",
    "        \n",
    "        if state.to_move == \"1\":\n",
    "            pit_index = move - 1\n",
    "            my_pits_range = self.p1_pits_index\n",
    "            my_mancala = self.p1_mancala_index\n",
    "            opponent_mancala = self.p2_mancala_index\n",
    "        else:\n",
    "            pit_index = self.p2_pits_index[1] - (move - 1)\n",
    "            my_pits_range = self.p2_pits_index\n",
    "            my_mancala = self.p2_mancala_index\n",
    "            opponent_mancala = self.p1_mancala_index\n",
    "        \n",
    "        stones = board[pit_index]\n",
    "        board[pit_index] = 0\n",
    "        \n",
    "        current_index = pit_index\n",
    "        \n",
    "        while stones > 0:\n",
    "            current_index = (current_index + 1) % len(board)\n",
    "            if current_index == opponent_mancala:\n",
    "                continue\n",
    "            board[current_index] += 1\n",
    "            stones -= 1\n",
    "        \n",
    "        next_player = \"2\" if state.to_move == \"1\" else \"1\"\n",
    "    \n",
    "        # Continuation rule\n",
    "        if current_index == my_mancala:\n",
    "            next_player = state.to_move\n",
    "        elif my_pits_range[0] <= current_index <= my_pits_range[1] and board[current_index] == 1:\n",
    "            opposite_index = len(board) - 2 - current_index\n",
    "            if board[opposite_index] > 0:\n",
    "                captured = board[current_index] + board[opposite_index]\n",
    "                board[current_index] = 0\n",
    "                board[opposite_index] = 0\n",
    "                board[my_mancala] += captured\n",
    "        \n",
    "        self.board = board.copy()\n",
    "        \n",
    "        return GameState(to_move=next_player, utility=0, board=tuple(board), moves=())\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"\n",
    "        Displays the board in a user-friendly format\n",
    "        \"\"\"\n",
    "        player_1_pits = self.board[self.p1_pits_index[0]: self.p1_pits_index[1]+1]\n",
    "        player_1_mancala = self.board[self.p1_mancala_index]\n",
    "        player_2_pits = self.board[self.p2_pits_index[0]: self.p2_pits_index[1]+1]\n",
    "        player_2_mancala = self.board[self.p2_mancala_index]\n",
    "\n",
    "        print('P1             P2')\n",
    "        print('      ____{}____     '.format(player_2_mancala))\n",
    "        for i in range(self.pits_per_player):\n",
    "            if i == self.pits_per_player - 1:\n",
    "                print('{} -> |_{}_|_{}_| <- {}'.format(i+1, player_1_pits[i], \n",
    "                                player_2_pits[-(i+1)], self.pits_per_player - i))\n",
    "            else:     \n",
    "                print('{} -> | {} | {} | <- {}'.format(i+1, player_1_pits[i], \n",
    "                                player_2_pits[-(i+1)], self.pits_per_player - i))\n",
    "            \n",
    "        print('          {}           '.format(player_1_mancala))\n",
    "        turn = 'P1' if self.state.to_move == \"1\" else 'P2'\n",
    "        print('Turn: ' + turn)\n",
    "        \n",
    "    def play_game(self):\n",
    "        \"\"\"Play an n-person, move-alternating game.\"\"\"\n",
    "        while True:\n",
    "            if self.state.to_move == \"1\":\n",
    "                player = self.players[0]\n",
    "                self.p1_moves += 1\n",
    "            else:\n",
    "                player = self.players[1]\n",
    "                self.p2_moves += 1\n",
    "                \n",
    "            move = player(self, self.state, self.depth)\n",
    "            self.state = self.result(self.state, move) \n",
    "            \n",
    "            if self.terminal_test(self.state):\n",
    "                score_diff = list(self.state.board)[self.p1_mancala_index] - list(self.state.board)[self.p2_mancala_index]\n",
    "                return {\n",
    "                    'score_diff': score_diff,\n",
    "                    'p1_moves': self.p1_moves,\n",
    "                    'p2_moves': self.p2_moves,\n",
    "                    'total_moves': self.p1_moves + self.p2_moves,\n",
    "                    'winner': 1 if score_diff > 0 else (2 if score_diff < 0 else 0)  # 0 = tie\n",
    "                }\n",
    "\n",
    "\n",
    "# Run trials and collect statistics\n",
    "num_trials = 10000\n",
    "plies = 1\n",
    "\n",
    "score_diffs = []\n",
    "p1_wins = 0\n",
    "p2_wins = 0\n",
    "ties = 0\n",
    "p1_moves_list = []\n",
    "p2_moves_list = []\n",
    "total_moves_list = []\n",
    "\n",
    "# --- ETA Setup ---\n",
    "start_time = time.time()\n",
    "# The trial count after which we consider the speed calculation stable enough\n",
    "# to start showing ETA. (e.g., after 100 trials)\n",
    "ETA_CALC_THRESHOLD = 100 \n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Converts a time in seconds to a human-readable HH:MM:SS format.\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    sec = int(seconds % 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{sec:02d}\"\n",
    "# -----------------\n",
    "\n",
    "print(f\"Running {num_trials} trials with depth = {plies}...\")\n",
    "# print(f\"Player 1: Alpha-Beta | Player 2: Random\\n\")\n",
    "\n",
    "for i in range(num_trials):\n",
    "    mancala_game = Mancala(players = [alpha_beta_player, random_player], depth=plies)\n",
    "    result = mancala_game.play_game()\n",
    "    \n",
    "    score_diffs.append(result['score_diff'])\n",
    "    p1_moves_list.append(result['p1_moves'])\n",
    "    p2_moves_list.append(result['p2_moves'])\n",
    "    total_moves_list.append(result['total_moves'])\n",
    "    \n",
    "    if result['winner'] == 1:\n",
    "        p1_wins += 1\n",
    "    elif result['winner'] == 2:\n",
    "        p2_wins += 1\n",
    "    else:\n",
    "        ties += 1\n",
    "\n",
    "    # --- Progress Bar and ETA Update ---\n",
    "    current_trials = i + 1\n",
    "    percent = current_trials / num_trials * 100\n",
    "    \n",
    "    progress_str = f\"\\rProgress: {current_trials}/{num_trials} trials run ({percent:.2f}%)\"\n",
    "    \n",
    "    if current_trials >= ETA_CALC_THRESHOLD:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        # Speed in trials per second\n",
    "        trials_per_second = current_trials / elapsed_time\n",
    "        \n",
    "        remaining_trials = num_trials - current_trials\n",
    "        # Estimated remaining time in seconds\n",
    "        eta_seconds = remaining_trials / trials_per_second\n",
    "        \n",
    "        eta_str = format_time(eta_seconds)\n",
    "        elapsed_str = format_time(elapsed_time)\n",
    "        \n",
    "        # Add ETA and Elapsed Time to the progress string\n",
    "        progress_str += f\" | Elapsed: {elapsed_str} | ETA: {eta_str}\"\n",
    "\n",
    "    sys.stdout.write(progress_str)\n",
    "    sys.stdout.flush()\n",
    "    # -----------------------------------\n",
    "\n",
    "# Print a final newline character to ensure the following output starts on a new line\n",
    "print()\n",
    "\n",
    "# Print results\n",
    "print(\"============================================================\")\n",
    "print(\"TRIAL RESULTS\")\n",
    "print(\"============================================================\")\n",
    "print(f\"\\nTotal Games Played: {num_trials}\")\n",
    "print(f\"\\nWin Statistics:\")\n",
    "print(f\"  Player 1 Wins: {p1_wins} ({p1_wins/num_trials*100:.1f}%)\")\n",
    "print(f\"  Player 2 Wins:      {p2_wins} ({p2_wins/num_trials*100:.1f}%)\")\n",
    "print(f\"  Ties:               {ties} ({ties/num_trials*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nScore Difference Statistics (P1 - P2):\")\n",
    "print(f\"  Total Sum:      {sum(score_diffs)}\")\n",
    "print(f\"  Average:        {np.mean(score_diffs):.2f}\")\n",
    "print(f\"  Std Dev:        {np.std(score_diffs):.2f}\")\n",
    "print(f\"  Min:            {min(score_diffs)}\")\n",
    "print(f\"  Max:            {max(score_diffs)}\")\n",
    "\n",
    "print(f\"\\nMoves Statistics:\")\n",
    "print(f\"  Average P1 Moves per Game:     {np.mean(p1_moves_list):.2f}\")\n",
    "print(f\"  Average P2 Moves per Game:     {np.mean(p2_moves_list):.2f}\")\n",
    "print(f\"  Average Total Moves per Game: {np.mean(total_moves_list):.2f}\")\n",
    "print(f\"  Total P1 Moves (all games):    {sum(p1_moves_list)}\")\n",
    "print(f\"  Total P2 Moves (all games):    {sum(p2_moves_list)}\")\n",
    "print(f\"  Total Moves (all games):       {sum(total_moves_list)}\")\n",
    "\n",
    "print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Random vs Random (100 games)\n",
    "\n",
    "**Win Statistics:**\n",
    "- Player 1 Wins: 48 (48.0%)\n",
    "- Player 2 Wins: 48 (48.0%)\n",
    "- Ties: 4 (4.0%)\n",
    "\n",
    "**Moves per Game:**\n",
    "- Average Total Moves: 44.29\n",
    "\n",
    "**Execution Time:** < 1 second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Minimax AI vs Random - 5 plies (100 games)\n",
    "\n",
    "**Win Statistics:**\n",
    "- AI Wins: 100 (100.0%)\n",
    "- Random Wins: 0 (0.0%)\n",
    "\n",
    "**Moves per Game:**\n",
    "- Average Total Moves: 37.91\n",
    "\n",
    "**Execution Time:** 00:00:52\n",
    "\n",
    "**Analysis:**\n",
    "The minimax AI at 5 plies wins every game against the random player, performing significantly better than random chance. Games finish faster than random vs random (37.91 vs 44.29 moves), showing the AI plays more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Alpha-Beta AI vs Random - 5 plies (100 games)\n",
    "\n",
    "**Win Statistics:**\n",
    "- AI Wins: 100 (100.0%)\n",
    "- Random Wins: 0 (0.0%)\n",
    "\n",
    "**Moves per Game:**\n",
    "- Average Total Moves: 38.99\n",
    "\n",
    "**Execution Time:** 00:00:06\n",
    "\n",
    "**Analysis:**\n",
    "The alpha-beta AI at 5 plies also wins every game with similar performance to minimax. The alpha-beta implementation is approximately 8.7x faster than minimax (6 seconds vs 52 seconds), demonstrating effective pruning while achieving identical win rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Alpha-Beta AI vs Random - 10 plies (100 games)\n",
    "\n",
    "**Win Statistics:**\n",
    "- AI Wins: 100 (100.0%)\n",
    "- Random Wins: 0 (0.0%)\n",
    "\n",
    "**Moves per Game:**\n",
    "- Average Total Moves: 33.48\n",
    "\n",
    "**Execution Time:** 00:11:22\n",
    "\n",
    "**Speed Comparison:**\n",
    "- Minimax at 5 plies: 52 seconds (0.52 sec/game)\n",
    "- Alpha-Beta at 5 plies: 6 seconds (0.06 sec/game)\n",
    "- Alpha-Beta at 10 plies: 682 seconds (6.82 sec/game)\n",
    "\n",
    "**Projected Minimax at 10 plies:**\n",
    "Based on the scaling factor from 5 to 10 plies, minimax would take approximately 98-100 minutes for 100 games.\n",
    "\n",
    "**Analysis:**\n",
    "At 10 plies, the AI maintains 100% win rate but finishes games even faster (33.48 moves vs 37.91-38.99 at 5 plies). The deeper search allows more efficient winning strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win Rate by Search Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16b44963e10>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_trials = 100\n",
    "\n",
    "win_percentage_per_ply = []\n",
    "\n",
    "plys_to_iterate_over = [2, 5, 10]\n",
    "\n",
    "for i in plys_to_iterate_over:\n",
    "    p1_wins = 0\n",
    "    p2_wins = 0\n",
    "    ties = 0\n",
    "    for j in range(num_trials):\n",
    "        mancala_game = Mancala(players = [alpha_beta_player, random_player], depth = i)\n",
    "        result = mancala_game.play_game()\n",
    "\n",
    "        if result['winner'] == 1:\n",
    "            p1_wins += 1\n",
    "        elif result['winner'] == 2:\n",
    "            p2_wins += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "\n",
    "    win_percentage_per_ply.append(p1_wins / num_trials)\n",
    "    \n",
    "\n",
    "plt.plot(plys_to_iterate_over, win_percentage_per_ply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Depth | AI Win Rate |\n",
    "|-------|-------------|\n",
    "| 2 plies | 100.0%   |\n",
    "| 5 plies | 100.0% |\n",
    "| 10 plies | 100.0% |\n",
    "\n",
    "**Explanation:**\n",
    "Across 2 plies, 5 plies, and 10 ply depths the AU achieve 100% win rates against random play. However, increasing depth from 5 to 10 plies reduces average game length from ~35 moves  to ~34 moves, and finally to 33.48 moves, indicating the deeper search finds more efficient paths to victory. The trade-off is significantly longer computation time (6 seconds for 1 ply vs 9 seconds for 5 plies vs 682 seconds for 10 plies). \n",
    "\n",
    "**Analysis of Trending:**\n",
    "Note that across 2, 5, and 10 plies, the Alpha-Beta player wins 100% of all 100 games in all three cases. This is expected, becuase the algorithm is far superior to a player playing at random. In fact, when running 10,000 trials at 1 ply, the random player only won 14 games and tied 2 times. When increasing the amount of plies, the odds of the random player winning by chance become exponentially more slim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Extra Credit - Updating the Utility Function\n",
    "\n",
    "For the first of the two extra credit opportunites, we decided of a way to update the utility function. The idea was to add a weighting system to what the AI values. Instead of the AI focusing only on the difference in the mancala pits, we also wanted to incorporate the fact that when one player clears their side of the board, all remaining stones on the other side of the board are immidiately collected and added to their mancala. If we were able to correctly weight the utility function so the AI cared about the mancala difference AND keeping stones on their side of the board towards the end of the game, we predicted we could improve the AI's performance.\n",
    "\n",
    "After a lot of trial and error, we decided on this:\n",
    "\n",
    "In each utility calculation, we sum across all regular pits and divide by the total number of stones in the game, which serves as a fraction that represents how much of the game has progressed. For the first 90% of the game, we use the original utility function, considering only the difference between stones in the mancala. However, in the last 10% of the game, the AI begins to increasingly also \"care\" about keeping stones on its side of the board. In doing this, we found a slight improvement in a number of statistics. See below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed Utility Function Statistics\n",
    "\n",
    "<b> <u> Running 10,000 trials with 1 ply with our original utility function yields: </u> </b>\n",
    "\n",
    "<u >Win Statistics: </u>\n",
    "\n",
    "  Player 1 Wins: 9982 (99.8%) \n",
    "\n",
    "  Player 2 Wins:      15 (0.1%)\n",
    "\n",
    "  Ties:               3 (0.0%)\n",
    "\n",
    "<u> Score Difference Statistics (P1 - P2): </u>\n",
    "\n",
    "  Total Sum:      231388\n",
    "\n",
    "  Average:        23.14\n",
    "\n",
    "  Std Dev:        6.17\n",
    "\n",
    "  Min:            -10\n",
    "\n",
    "  Max:            40\n",
    "\n",
    "<u> Moves Statistics: </u>\n",
    "\n",
    "  Average P1 Moves per Game:     19.16\n",
    "\n",
    "  Average P2 Moves per Game:     13.88\n",
    "\n",
    "  Average Total Moves per Game: 33.04\n",
    "\n",
    "  Total P1 Moves (all games):    191606\n",
    "\n",
    "  Total P2 Moves (all games):    138782\n",
    "\n",
    "  Total Moves (all games):       330388\n",
    "\n",
    "<b> <u> With our updated utlity function, running 10,000 trials with 1 ply instead yields: </b> </u>\n",
    "\n",
    "<u> Win Statistics: </u>\n",
    "\n",
    "  Player 1 Wins: 9985 (99.9%)\n",
    "\n",
    "  Player 2 Wins:      14 (0.1%)\n",
    "\n",
    "  Ties:               1 (0.0%)\n",
    "\n",
    "<u> Score Difference Statistics (P1 - P2): </u>\n",
    "\n",
    "  Total Sum:      232179\n",
    "\n",
    "  Average:        23.22\n",
    "\n",
    "  Std Dev:        6.06\n",
    "\n",
    "  Min:            -9\n",
    "\n",
    "  Max:            41\n",
    "\n",
    "<u> Moves Statistics: </u>\n",
    "\n",
    "  Average P1 Moves per Game:     19.14\n",
    "\n",
    "  Average P2 Moves per Game:     13.88\n",
    "\n",
    "  Average Total Moves per Game: 33.03\n",
    "\n",
    "  Total P1 Moves (all games):    191437\n",
    "\n",
    "  Total P2 Moves (all games):    138826\n",
    "\n",
    "  Total Moves (all games):       330263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although a very minor improvement, you can see that our updated utility function resulted in:\n",
    "\n",
    "Player 1 Wins: `9982 (99.8%)` -> `9985 (99.9%)`\n",
    "\n",
    "Average P1 Moves per Game: `19.16` -> `19.14`\n",
    "\n",
    "Average of Score Difference: `23.14` -> `23.22`\n",
    "\n",
    "Std Dev: `6.17` -> `6.06`\n",
    "\n",
    "Essentially, these numbers tell us that our AI player is (on average) now winning more games by a higher margin in less moves. The standard deviation also went down, meaning that our games are playing more consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Extra Credit: Implement the continuation rule fully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second extra credit opportunity, we implemented the continuation rule.\n",
    "\n",
    "Implementing this was simple, we simply added this condition to our `result` function:\n",
    "\n",
    "`if current_index == my_mancala: \n",
    "    next_player = state.to_move`\n",
    "\n",
    "If the while loop ends on the player's mancala, we simply revert the operation done above this code to flip the player, effectively flipping the next_player back to the current player and maintaining their turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of implementing the continuation rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search Trials Comparison\n",
    "## 10 Plies - With vs Without Rule Change\n",
    "\n",
    "---\n",
    "\n",
    "## WITH CHANGE\n",
    "\n",
    "**Progress:** 100/100 trials run (100.00%) | Elapsed: 00:11:22 | ETA: 00:00:00\n",
    "\n",
    "### Trial Results\n",
    "\n",
    "**Total Games Played:** 100\n",
    "\n",
    "#### Win Statistics\n",
    "- **Player 1 Wins:** 100 (100.0%)\n",
    "- **Player 2 Wins:** 0 (0.0%)\n",
    "- **Ties:** 0 (0.0%)\n",
    "\n",
    "#### Score Difference Statistics (P1 - P2)\n",
    "- **Total Sum:** 2192\n",
    "- **Average:** 21.92\n",
    "- **Std Dev:** 4.96\n",
    "- **Min:** 7\n",
    "- **Max:** 34\n",
    "\n",
    "#### Moves Statistics\n",
    "- **Average P1 Moves per Game:** 17.16\n",
    "- **Average P2 Moves per Game:** 16.32\n",
    "- **Average Total Moves per Game:** 33.48\n",
    "- **Total P1 Moves (all games):** 1716\n",
    "- **Total P2 Moves (all games):** 1632\n",
    "- **Total Moves (all games):** 3348\n",
    "\n",
    "---\n",
    "\n",
    "## BEFORE CHANGE\n",
    "\n",
    "**Progress:** 100/100 trials run (100.00%) | Elapsed: 00:13:20 | ETA: 00:00:00\n",
    "\n",
    "### Trial Results\n",
    "\n",
    "**Total Games Played:** 100\n",
    "\n",
    "#### Win Statistics\n",
    "- **Player 1 Wins:** 100 (100.0%)\n",
    "- **Player 2 Wins:** 0 (0.0%)\n",
    "- **Ties:** 0 (0.0%)\n",
    "\n",
    "#### Score Difference Statistics (P1 - P2)\n",
    "- **Total Sum:** 2282\n",
    "- **Average:** 22.82\n",
    "- **Std Dev:** 4.85\n",
    "- **Min:** 11\n",
    "- **Max:** 33\n",
    "\n",
    "#### Moves Statistics\n",
    "- **Average P1 Moves per Game:** 16.75\n",
    "- **Average P2 Moves per Game:** 15.93\n",
    "- **Average Total Moves per Game:** 32.68\n",
    "- **Total P1 Moves (all games):** 1675\n",
    "- **Total P2 Moves (all games):** 1593\n",
    "- **Total Moves (all games):** 3268\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Comparison\n",
    "\n",
    "| Metric | With Change | Before Change | Difference |\n",
    "|--------|-------------|---------------|------------|\n",
    "| Avg Score Difference | 21.92 | 22.82 | -0.90 |\n",
    "| Std Dev | 4.96 | 4.85 | +0.11 |\n",
    "| Avg Total Moves | 33.48 | 32.68 | +0.80 |\n",
    "| Execution Time | 00:11:22 | 00:13:20 | -1:58 (faster) |\n",
    "\n",
    "\n",
    "Player 1 takes more moves as since they realise they can go again if they end in their own pit, so they try and do that, which causes P1 to move more, and win more too (though the win-rates are equal as we only ran 100 trials due to high-ply counts)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
